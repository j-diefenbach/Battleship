{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FICee1SQ07f"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/UNSW-COMP9418/Week03/blob/main/COMP9418_W03_Variable_Elimination_In_Graphical_Models.ipynb)\n",
        "\n",
        "# Variable Elimination in Graphical Models\n",
        "\n",
        "**COMP9418 W03 Tutorial**\n",
        "\n",
        "- Instructor: Gustavo Batista\n",
        "- School of Computer Science and Engineering, UNSW Sydney\n",
        "- Notebook designed by Gustavo Batista and Jeremy Gillen\n",
        "- Last Update 6th September 2022\n",
        "$$\n",
        "% macros\n",
        "\\newcommand{\\indep}{\\perp \\!\\!\\!\\perp}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgEnSaAtQ07g"
      },
      "source": [
        "In this week's tutorial, we will implement and investigate the efficiency of the Variable Elimination (VE) algorithm and the min-degree heuristic for finding a good elimination order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYPPnTIhQ07h"
      },
      "source": [
        "# Technical prerequisites\n",
        "\n",
        "You will need certain packages installed to run this notebook.\n",
        "\n",
        "If you are using Google Colab or ``conda``'s default [full installation](https://conda.io/docs/install/full.html), these requirements should all be satisfied already.\n",
        "\n",
        "If you are using ``virtualenv`` or other native package management, you may need to run this command:\n",
        "\n",
        "```python\n",
        "pip3 install matplotlib\n",
        "```\n",
        "\n",
        "To render a visualisation of some graphical models, you also need to install Graphviz [download page](http://www.graphviz.org/download). We have already used this library in the Week 0 Tutorial; thus, you should have it installed.\n",
        "\n",
        "Once we have done all that, we import some useful modules for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IPugzk_6Q07h"
      },
      "outputs": [],
      "source": [
        "# combinatorics\n",
        "from itertools import product, combinations, permutations\n",
        "# visualise plots\n",
        "import matplotlib.pyplot as plt\n",
        "# math library to get access to math.inf\n",
        "import math\n",
        "# library to check if a file exists\n",
        "import os.path\n",
        "# library to copy complex objects\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Wwe-QrQ07h"
      },
      "source": [
        "Import classes from `DiscreteFactors.py`, `Graph.py` and `BayesNet.py` developed in previous tutorials. If you are using Colab, upload the files by clicking the \"files\" ![File](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/file.png) button on the left side of the page, then the \"upload files\" ![Upload](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/upload.png)\n",
        "button. Then select the relevant Python files.\n",
        "\n",
        "Otherwise, you can download it from GitHub by executing the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sy0hn9vhQ07i",
        "outputId": "9f8d21ba-8d65-4f8c-dedd-055e6fbd0ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading DiscreteFactors.py...\n",
            "Downloading Graph.py...\n",
            "Downloading BayesNet.py...\n"
          ]
        }
      ],
      "source": [
        "# Only run this cell if you do not want to use your libraries and\n",
        "# prefer to download our implementation from GitHub\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "base_url = \"https://raw.githubusercontent.com/UNSW-COMP9418/libraries/main/\"\n",
        "files = [\"DiscreteFactors.py\", \"Graph.py\", \"BayesNet.py\"]\n",
        "\n",
        "for file in files:\n",
        "    url = base_url + file\n",
        "    print(f\"Downloading {file}...\")\n",
        "    urllib.request.urlretrieve(url, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5GWYIAMrQ07i"
      },
      "outputs": [],
      "source": [
        "from DiscreteFactors import Factor\n",
        "from Graph import Graph\n",
        "from BayesNet import BayesNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45b2_5BKQ07i"
      },
      "source": [
        "# The ICU network\n",
        "\n",
        "Once again, we will use a subset of the ICU-Alarm network. You should remember this Bayesian Network from the Week 3 tutorial. In any case, this is a graphical representation of the nine nodes we will use in this tutorial.\n",
        "\n",
        "![ICU Graph](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/ICU_graph.png \"Graph exercise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHZBqH6rQ07i"
      },
      "source": [
        "In the Week 3 Tutorial, we learned the ICU Alarm network parameters from data. This week, we will simplify the code and provide the conditional probability tables (CPTs) directly. We defined a BayesNet named `ICU_Net` with the CPTs of the nine variables in the subset of the ICU-Alarm network.\n",
        "\n",
        "The `ICU_Net.factors` dictionary associates a key, in this case, the name of the child node, to each factor. Initially, each factor is a CPT. However, as we multiply factors, we will generate tables of different formats. Some of these factors will not be probability distributions. Therefore, we use the name \"factor\" to designate a generalisation of the idea of a CPT.\n",
        "\n",
        "As we work with factors, our code will be equally prepared to work with Bayesian and Markov networks, which we will see in a future lecture.\n",
        "\n",
        "Let's start by defining the Bayes Net for the ICU-Alarm network. Instead of learning the parameters from data, we will define them directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hydEAulMQ07i"
      },
      "outputs": [],
      "source": [
        "# define Bayes Net Graph\n",
        "graph = Graph({\n",
        "    'L': ['S', 'V'],\n",
        "    'H': ['S', 'V'],\n",
        "    'S': ['O'],\n",
        "    'V': ['C', 'O'],\n",
        "    'O': ['B'],\n",
        "    'A': ['T'],\n",
        "    'T': ['B'],\n",
        "    'C': [],\n",
        "    'B': [],\n",
        "})\n",
        "# Define outcome space of each random variable\n",
        "outcomeSpace = dict(\n",
        "    H=(0,1),\n",
        "    L=(0,1),\n",
        "    A=(0,1),\n",
        "    V=(0,1),\n",
        "    S=(0,1),\n",
        "    T=(0,1),\n",
        "    C=(0,1,2),\n",
        "    O=(0,1,2),\n",
        "    B=(0,1,2),\n",
        ")\n",
        "# Initialize Bayesian Network object\n",
        "ICU_Net = BayesNet(graph, outcomeSpace)\n",
        "\n",
        "# Add each factor one by one to the ICU_Net object\n",
        "h = Factor(('H',), outcomeSpace)\n",
        "h[0] = 0.8\n",
        "h[1] = 0.2\n",
        "ICU_Net.factors['H'] = h\n",
        "\n",
        "v = Factor(('L', 'H', 'V'), outcomeSpace)\n",
        "v[0, 0, 0] = 0.05\n",
        "v[0, 0, 1] = 0.95\n",
        "v[0, 1, 0] = 0.99\n",
        "v[0, 1, 1] = 0.01\n",
        "v[1, 0, 0] = 0\n",
        "v[1, 0, 1] = 1\n",
        "v[1, 1, 0] = 1\n",
        "v[1, 1, 1] = 0\n",
        "ICU_Net.factors['V'] = v\n",
        "\n",
        "c = Factor(('V', 'C'), outcomeSpace)\n",
        "c[0, 0] = 0.94\n",
        "c[0, 1] = 0.04\n",
        "c[0, 2] = 0.02\n",
        "c[1, 0] = 0.02\n",
        "c[1, 1] = 0.26\n",
        "c[1, 2] = 0.72\n",
        "ICU_Net.factors['C'] = c\n",
        "\n",
        "l = Factor(('L',), outcomeSpace)\n",
        "l[0] = 0.95\n",
        "l[1] = 0.05\n",
        "ICU_Net.factors['L'] = l\n",
        "\n",
        "s = Factor(('L','H','S'), outcomeSpace)\n",
        "s[0, 0, 0] = 0.04\n",
        "s[0, 0, 1] = 0.96\n",
        "s[0, 1, 0] = 0.48\n",
        "s[0, 1, 1] = 0.52\n",
        "s[1, 0, 0] = 0.95\n",
        "s[1, 0, 1] = 0.05\n",
        "s[1, 1, 0] = 0\n",
        "s[1, 1, 1] = 1\n",
        "ICU_Net.factors['S'] = s\n",
        "\n",
        "o = Factor(('S', 'V', 'O'), outcomeSpace)\n",
        "o[0, 0, 0] = 0.97\n",
        "o[0, 0, 1] = 0.01\n",
        "o[0, 0, 2] = 0.02\n",
        "o[0, 1, 0] = 0.78\n",
        "o[0, 1, 1] = 0.19\n",
        "o[0, 1, 2] = 0.03\n",
        "o[1, 0, 0] = 0.22\n",
        "o[1, 0, 1] = 0.76\n",
        "o[1, 0, 2] = 0.02\n",
        "o[1, 1, 0] = 0.01\n",
        "o[1, 1, 1] = 0.01\n",
        "o[1, 1, 2] = 0.98\n",
        "ICU_Net.factors['O'] = o\n",
        "\n",
        "t = Factor(('A','T'), outcomeSpace)\n",
        "t[0, 0] = 0.30\n",
        "t[0, 1] = 0.70\n",
        "t[1, 0] = 1\n",
        "t[1, 1] = 0\n",
        "ICU_Net.factors['T'] = t\n",
        "\n",
        "b = Factor(('O', 'T', 'B'), outcomeSpace)\n",
        "b[0, 0, 0] = 1\n",
        "b[0, 0, 1] = 0\n",
        "b[0, 0, 2] = 0\n",
        "b[0, 1, 0] = 0.30\n",
        "b[0, 1, 1] = 0.62\n",
        "b[0, 1, 2] = 0.08\n",
        "b[1, 0, 0] = 0.93\n",
        "b[1, 0, 1] = 0.07\n",
        "b[1, 0, 2] = 0\n",
        "b[1, 1, 0] = 0.02\n",
        "b[1, 1, 1] = 0.49\n",
        "b[1, 1, 2] = 0.49\n",
        "b[2, 0, 0] = 0.90\n",
        "b[2, 0, 1] = 0.08\n",
        "b[2, 0, 2] = 0.02\n",
        "b[2, 1, 0] = 0.01\n",
        "b[2, 1, 1] = 0.08\n",
        "b[2, 1, 2] = 0.91\n",
        "ICU_Net.factors['B'] = b\n",
        "\n",
        "a = Factor(('A',), outcomeSpace)\n",
        "a[0] = 0.99\n",
        "a[1] = 0.01\n",
        "ICU_Net.factors['A'] = a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMJDATVcQ07i"
      },
      "source": [
        "# Elimination Order Width\n",
        "\n",
        "Let's start our code with a straightforward function that will help us to build more complex ones. An essential concept in variable elimination is the `width` of an elimination order. It is defined as the number of variables (after summation) of the largest factor created during the execution of the Variable Elimination (VE) algorithm.\n",
        "\n",
        "The `width` of an elimination order is a measure of its quality. Elimination orders with small `width` tend to be more efficient than those with larger `width`.\n",
        "\n",
        "We can efficiently compute the `width` of an elimination order by simulating the VE algorithm. The idea is that we will keep track of the factor domains, but we will not perform the multiplication and summation of factors.\n",
        "\n",
        "## Exercise\n",
        "\n",
        "We will implement our first function, `width`, that returns the width of an elimination order.\n",
        "This function takes an elimination order (a list of variable names) and performs the Variable Elimination process to determine the width of this order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mjm_XRBQ07j"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def width(self, order):\n",
        "        \"\"\"\n",
        "        argument\n",
        "        `order`, a list of variable names specifying an elimination order.\n",
        "\n",
        "        Returns the width of the elimination order, i.e., the number of variables of the largest factor\n",
        "        \"\"\"\n",
        "        # Initialize w, a variable that has a width of the elimination order\n",
        "        w = 0\n",
        "        # Let's make a list of tuples, where each tuple is a factor domain. Create one tuple for each factor in the BN\n",
        "        factorList = ... # TODO 1 or 2 lines\n",
        "        # We process the factor in elimination order\n",
        "        for var in order:\n",
        "            # This is the domain of the new factor. We use sets as it is handy to eliminate duplicate variables\n",
        "            newFactorDom = set()\n",
        "            # A list to keep track of all the factors we will keep for the next iteration (all factors not containing `var`)\n",
        "            updatedFactorsList = list()\n",
        "\n",
        "            # Lets iterate over all factors\n",
        "            for f_dom in factorList:\n",
        "                # and select the ones that have the variable to be eliminated\n",
        "                if var in f_dom:\n",
        "                    # Merge the selected domain `f_dom` into the `newFactorDomain` set, simulating a join operation\n",
        "                    ... # TODO 1 line\n",
        "                else:\n",
        "                    # since it doesn't contain `var`, we add the `var` factor to the updatedFactorsList to be processed in the next iteration\n",
        "                    ... # TODO 1 line\n",
        "\n",
        "            # Now, we need to remove var from the domain of the new factor. We are simulating a summation\n",
        "            ...         # TODO Remove var from the set newFactorDom by calling the method remove(). 1 line\n",
        "            # Let's check if we have found a new largest factor\n",
        "            if len(newFactorDom) > w:\n",
        "                w = len(newFactorDom)\n",
        "            # add the new combined factor domain to the list\n",
        "            updatedFactorsList.append(newFactorDom)\n",
        "            # replace factor list with updated factor list (getting rid of all factors containing var)\n",
        "            factorList = updatedFactorsList\n",
        "\n",
        "        return w\n",
        "\n",
        "# reinitialise ICU_net so that it has width function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "######################\n",
        "# Test code\n",
        "\n",
        "print(\"Elimination order width: %d\" % ICU_Net.width(['V', 'H', 'S', 'L', 'O', 'A', 'T', 'B', 'C']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU7_O8X8Q07j"
      },
      "source": [
        "If you implemented your code correctly, you should see the following output:\n",
        "\n",
        "```\n",
        "Elimination order width: 5\n",
        "```\n",
        "\n",
        "There are several observations about the `width` function:\n",
        "\n",
        "1. Each iteration eliminates one variable in the list `order`.\n",
        "2. The elimination is achieved by scanning `factors` and finding all factors whose domain has the elimination variable.\n",
        "3. We simulate the join operation by creating a list with all variables present in factors that contain the elimination variable.\n",
        "4. We remove the elimination variable before we compute the `width`. Therefore, we obtain the value according to the definition.\n",
        "5. We simulate the creation of a new factor and insert this dummy factor into the dictionary of factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0kmqpwQ07j"
      },
      "source": [
        "# Variable Elimination (VE) Algorithm\n",
        "\n",
        "Let's use the previous function to implement the first version of our VE algorithm. We will need the join and marginalise operations implemented in the earlier tutorials in the Factor class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1py-2a9Q07j"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "We are now in a position to implement the function `VE`, which will execute the Variable Elimination algorithm for a given variable order. The code is very similar to the `width` function, except instead of only keeping track of the factor domains, we will keep track of the whole factor objects.\n",
        "\n",
        "As part of this exercise, we will use global variables `muls` and `adds` to count the number of multiplications and additions that will occur during the join and marginalise operations. We will use this to measure the algorithm's efficiency. Complete this part of the algorithm after the function is working. For this exercise, it may be useful to know that if `f` is a factor object, you can use `f.table.size` to get the number of elements in the table that makes up that factor. This is useful when determining how many multiplications occurred in a join operation and how many additions took place in a marginalise operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GExQiZiqQ07j"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def VE(self, order):\n",
        "        \"\"\"\n",
        "        argument\n",
        "        `order`, a list of variable names specifying an elimination order.\n",
        "\n",
        "        Returns a single factor, the which remains after eliminating all other factors\n",
        "        \"\"\"\n",
        "        global muls, adds\n",
        "        # Let's make a list of all factor objects\n",
        "        factorList = ... # 1 line\n",
        "\n",
        "        for var in order:\n",
        "            # We create an empty factor as an accumulator\n",
        "            newFactor = Factor(tuple(), self.outcomeSpace)\n",
        "            first = True\n",
        "            # A list to keep track of all the factors we will keep for the next step\n",
        "            updatedFactorsList = list()\n",
        "\n",
        "            for f in factorList:\n",
        "                # and select the ones that have the variable to be eliminated\n",
        "                if var in f.domain:\n",
        "                    # join the factor `f` with the accumulator `newFactor`\n",
        "                    newFactor = ... # TODO 1 line\n",
        "                    if not first:\n",
        "                        muls += newFactor.table.size # keep track of multiplications being done with each join operation\n",
        "                    first = False\n",
        "\n",
        "                else:\n",
        "                    # since the factor `f` doesn't contain `var`, we will keep it for next iteration\n",
        "                    ... # TODO 1 line\n",
        "\n",
        "            # Now, we need to remove var from the domain of the new factor.\n",
        "            adds += newFactor.table.size # keep track of the number of additions being done in the following marginalization\n",
        "            newFactor = ... # TODO marginalize out `var`\n",
        "            # append the new combined factor to the factor list\n",
        "            updatedFactorsList.append(newFactor)\n",
        "            # replace factorList with the updated factor list, ready for the next iteration\n",
        "            factorList = updatedFactorsList\n",
        "        # for the final step, we join all remaining factors (usually there will only be one factor remaining)\n",
        "        returnFactor = Factor(tuple(), self.outcomeSpace)\n",
        "        for f in factorList:\n",
        "            returnFactor = returnFactor*f\n",
        "        return returnFactor\n",
        "\n",
        "\n",
        "######################\n",
        "# Test code\n",
        "\n",
        "# reinitialise ICU_net so that it has VE function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "adds = 0\n",
        "muls = 0\n",
        "\n",
        "print(ICU_Net.VE(['V', 'H', 'S', 'L', 'O', 'A', 'T', 'B']))\n",
        "print(\"Number of additions: %d\" %adds)\n",
        "print(\"Number of multiplications: %d\" %muls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIAyDk77Q07j"
      },
      "source": [
        "If you implemented your code correctly, you should see the following output:\n",
        "\n",
        "```\n",
        "╒═════╤══════════╕\n",
        "│   C │       Pr │\n",
        "╞═════╪══════════╡\n",
        "│   0 │ 0.237212 │\n",
        "├─────┼──────────┤\n",
        "│   1 │ 0.208058 │\n",
        "├─────┼──────────┤\n",
        "│   2 │ 0.55473  │\n",
        "╘═════╧══════════╛\n",
        "\n",
        "Number of additions: 355\n",
        "Number of multiplications: 342\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t17JNPKPQ07j"
      },
      "source": [
        "# Inference by Enumeration\n",
        "\n",
        "It is unclear how good these numbers of additions and multiplications are. We need to compare them with other elimination orders. However, we will first compute the number of operations required by inference by enumeration. Inference by enumeration will provide an upper bound on the number of operations, as well as an indication of the VE efficiency.\n",
        "\n",
        "A reminder that inference by enumeration is the algorithm that joins all factors before eliminating any variables. We implemented this algorithm last week; this time, we will count `adds` and `muls`.\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Implement the `inferenceByEnum` function by changing the order of the operations. Join all factors first and then eliminate the variables in `order`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1heJSBGTQ07j"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def inferenceByEnum(self, order):\n",
        "        global muls, adds\n",
        "        # Let's make a list of factors\n",
        "        factorList = ... # TODO 1 line\n",
        "\n",
        "        # Create an empty factor as accumulator\n",
        "        newFactor = ... # TODO 1 line\n",
        "\n",
        "        first = True\n",
        "        # Lets iterate over all factors\n",
        "        for f in factorList:\n",
        "            newFactor = ... # TODO join 1 line\n",
        "            if not first:\n",
        "                ... # TODO count multiplications 1 line\n",
        "            first = False\n",
        "\n",
        "        for var in order:\n",
        "            # Now, we need to remove var from the domain of the new factor.\n",
        "            ... # TODO count additions 1 line\n",
        "            newFactor = ... # TODO marginalize 1 line\n",
        "\n",
        "        return newFactor\n",
        "\n",
        "\n",
        "######################\n",
        "# Test code\n",
        "\n",
        "# reinitialise ICU_net so that it has VE function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "adds = 0\n",
        "muls = 0\n",
        "print(ICU_Net.inferenceByEnum(['V', 'H', 'S', 'L', 'O', 'A', 'T', 'B']))\n",
        "print(\"Number of additions: %d\" %adds)\n",
        "print(\"Number of multiplications: %d\" %muls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orFafmaCQ07j"
      },
      "source": [
        "If you implemented your code correctly, you should see the following output:\n",
        "\n",
        "```\n",
        "╒═════╤══════════╕\n",
        "│   C │       Pr │\n",
        "╞═════╪══════════╡\n",
        "│   0 │ 0.237212 │\n",
        "├─────┼──────────┤\n",
        "│   1 │ 0.208058 │\n",
        "├─────┼──────────┤\n",
        "│   2 │ 0.55473  │\n",
        "╘═════╧══════════╛\n",
        "\n",
        "Number of additions: 3411\n",
        "Number of multiplications: 4280\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT7uiGnYQ07j"
      },
      "source": [
        "# Width and Number of Operations\n",
        "\n",
        "An interesting question is how the width measure correlates with the actual number of addition and multiplication operations. We can plot these two measures of inference efficiency.\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Compare the number of multiplications with the width of the elimination order. We have created a piece of code that does part of the work for you. The idea is to generate all possible permutations of the elimination list and measure the width and number of multiplications. We will work with only seven variables since the number of permutations grows exponentially with the number of variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRqKIJ85Q07j"
      },
      "outputs": [],
      "source": [
        "# List with width of all permutations of the elimination list ('V', 'H', 'S', 'L', 'O', 'A', 'T')\n",
        "widthList = []\n",
        "# List with number of multiplications ofr the same permutations\n",
        "mulList = []\n",
        "for i, perm in enumerate(permutations(('V', 'H', 'S', 'L', 'O', 'A', 'T'))):\n",
        "    # Call the width function for the permutation in p\n",
        "    w = ... # TODO compute width of order. 1 line\n",
        "    widthList.append(w)\n",
        "    # Initialize muls\n",
        "    muls = 0\n",
        "    # Call the VE function to compute the number of multiplications\n",
        "    ... # TODO 1 line\n",
        "    mulList.append(muls)\n",
        "    # Print some information since it may take some time to finish\n",
        "    if (i % 100 == 0):\n",
        "        print(\"%6d %6d %1.6f\" % (i, w, muls))\n",
        "# Generate plots\n",
        "plt.plot(widthList, mulList, 'ro')\n",
        "plt.xlabel(\"Width\")\n",
        "plt.ylabel(\"Number of muls\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5muivzR1Q07j"
      },
      "outputs": [],
      "source": [
        "# List with width of all permutations of the elimination list ('V', 'H', 'S', 'L', 'O', 'A', 'T')\n",
        "widthList = []\n",
        "# List with number of multiplications ofr the same permutations\n",
        "mulList = []\n",
        "for i, perm in enumerate(permutations(('V', 'H', 'S', 'L', 'O', 'A', 'T'))):\n",
        "    # Call the width function for the permutation in p\n",
        "    w = ICU_Net.width(perm)\n",
        "    widthList.append(w)\n",
        "    # Initialize muls\n",
        "    muls = 0\n",
        "    # Call the VE function to copermte the number of multpermications\n",
        "    ICU_Net.VE(perm)\n",
        "    mulList.append(muls)\n",
        "    # Print some information since it may take some time to finish\n",
        "    if (i % 100 == 0):\n",
        "        print(\"%6d %6d %1.6f\" % (i, w, muls))\n",
        "# Generate plots\n",
        "plt.plot(widthList, mulList, 'ro')\n",
        "plt.xlabel(\"Width\")\n",
        "plt.ylabel(\"Number of muls\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJABZs7sQ07j"
      },
      "source": [
        "We can see that width correlates well with the number of multiplications. More importantly, small widths have a small variance, indicating good performance independently of a specific order. The plot appears to grow exponentially.\n",
        "\n",
        "# Min-degree heuristic\n",
        "\n",
        "Having a good ordering is central to VE algorithm performance. However, it is known that finding the best order is an NP-hard problem.\n",
        "\n",
        "For a small number of variables, we can use the `width` function to test all possible orderings. The next cell implements such an approach for all nine variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG4yQeixQ07k"
      },
      "outputs": [],
      "source": [
        "minW = math.inf\n",
        "for perm in permutations(['V', 'H', 'S', 'L', 'O', 'A', 'T', 'B', 'C']):\n",
        "    # Call the width function for the permutation in p\n",
        "    w = ICU_Net.width(perm)\n",
        "    if (w < minW):\n",
        "        minP = perm\n",
        "        minW = w\n",
        "print(\"Order with minimal width %d: \" % minW)\n",
        "\n",
        "print(minP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4I8w4IXQ07k"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "For larger networks, we will need to use a heuristic approach. One of the simplest is known as min-degree. Min-degree and several other ordering heuristics operate over an undirected graph known as an *interaction graph*.\n",
        "\n",
        "The interaction graph is simply a graph in which the nodes are variables, and the edges connect variables that appear in the domain of the same factor.\n",
        "\n",
        "We will start implementing `interactionGraph`, a function that receives a dictionary of factors and returns an interaction graph. We use the same adjacency list representation as in the Week 0 tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFHchtLoQ07k"
      },
      "outputs": [],
      "source": [
        "# add a function to BayesNet to get interaction graph\n",
        "class BayesNet(BayesNet):\n",
        "    def interactionGraph(self):\n",
        "        '''\n",
        "        Returns the interaction graph for this network.\n",
        "        There are two ways to implement this function:\n",
        "        - Iterate over factors and check which vars are in the same factors\n",
        "        - Start with the directed graph, make it undirected and moralise it\n",
        "        '''\n",
        "        # Initialise an empty graph\n",
        "        g = Graph()\n",
        "        # Add each node to the graph\n",
        "        for var in self.factors.keys():\n",
        "            ... # TODO add node. 1 line\n",
        "        for factor in self.factors.values():\n",
        "            # for every pair of vars in the domain\n",
        "            for var1 in factor.domain:\n",
        "                for var2 in factor.domain:\n",
        "                    # check if connection already exists\n",
        "                    if var1 != var2 and var1 not in g.children(var2):\n",
        "                        # add an *undirected* connection\n",
        "                        ... # TODO 1 line\n",
        "        return g\n",
        "\n",
        "\n",
        "##############\n",
        "# Test code\n",
        "\n",
        "# reinitialise ICU_net so that it has interactionGraph function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "# List of positions for each node\n",
        "# We use node positions to replicate the previous figure\n",
        "# This can be removed if the nodes do not need to be presented in a specific order\n",
        "pos = {\n",
        "    'B': '1,0!',\n",
        "    'O': '0,1!',\n",
        "    'C': '1,1!',\n",
        "    'T': '2,1!',\n",
        "    'S': '0,2!',\n",
        "    'V': '1,2!',\n",
        "    'A': '2,2!',\n",
        "    'L': '0,3!',\n",
        "    'H': '1,3!',\n",
        "}\n",
        "ig = ICU_Net.interactionGraph()\n",
        "ig.show(directed=False, positions=pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WKjSaruQ07k"
      },
      "source": [
        "If your code is correct, you should see the following induced graph:\n",
        "\n",
        "![IG Graph](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/IG.png \"Graph exercise\")\n",
        "\n",
        "Also, this is the ICU network graph for reference:\n",
        "\n",
        "![ICU Graph](https://raw.githubusercontent.com/UNSW-COMP9418/Week03/main/img/ICU_graph.png \"Graph exercise\")\n",
        "\n",
        "From this representation, we can see that a min-degree heuristic should start eliminating variables such as `A` and `C`.\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Now, let's implement the `minDegree` function that receives an induced graph and returns a list with a variable elimination order.\n",
        "\n",
        "This function will suggest the nodes with the smallest degree first. Remember that the degree of a node is the number of edges connected to that node. Every time we select a node as the next to be eliminated, we need to remove that node from the graph. This operation will reduce the degree of the nodes directly connected to the removed one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5QLIsJ-Q07k"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def minDegree(self):\n",
        "        # First get the interaction graph\n",
        "        ig = self.interactionGraph()\n",
        "        # Initialize order with empty list. This variable will have the answer in the end of the execution\n",
        "        order = []\n",
        "        # While the induced graph has nodes to be eliminated\n",
        "        while len(ig) > 0:\n",
        "            # Initialize minDegree with a large number: math.inf\n",
        "            minDegree = math.inf\n",
        "            for var in ig:\n",
        "                # Test if var has a degree smaller than minDegree\n",
        "                if len(ig.children(var)) < minDegree:\n",
        "                    # We have found a new candidate to be the next eliminated variable. Let's save its degree and name\n",
        "                    minDegree = ... # TODO 1 line\n",
        "                    minVar = ... # TODO 1 line\n",
        "            # We need to connect the neighbours of minVar, let us start using combinations function to find all pairs of minVar's neighbours\n",
        "            for var1, var2 in combinations(ig.children(minVar), 2):\n",
        "                # Check if these neighbour are not already connected by an edge\n",
        "                if var1 not in ig.children(var2):\n",
        "                    # add edge\n",
        "                    ... # TODO 1 line\n",
        "            # Insert into order the variable in minVar\n",
        "            order.append(...) # TODO\n",
        "            # Now, we need to remove minVar from the adjacency list of every node\n",
        "            ig.remove_node(...) # TODO\n",
        "        return order\n",
        "\n",
        "\n",
        "####################\n",
        "# Test code\n",
        "\n",
        "# reinitialise ICU_net so that it has minDegree function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "print(ICU_Net.minDegree())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCmGav6Q07k"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "```\n",
        "['A', 'C', 'T', 'B', 'O', 'H', 'L', 'V', 'S']\n",
        "```\n",
        "or\n",
        "```\n",
        "['C', 'A', 'T', 'B', 'O', 'H', 'V', 'L', 'S']\n",
        "```\n",
        "We can compare the width of the ordering provided by the min-degree heuristic to some other order:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLVSftK1Q07k"
      },
      "outputs": [],
      "source": [
        "print(ICU_Net.width(('V', 'H', 'S', 'L', 'O', 'A', 'T', 'B', 'C')))\n",
        "order = ICU_Net.minDegree()\n",
        "print(ICU_Net.width(order))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sfbO5E_Q07k"
      },
      "source": [
        "Similarly, we can compare the number of additions and multiplications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA2ZCQNjQ07k"
      },
      "outputs": [],
      "source": [
        "adds = 0\n",
        "muls = 0\n",
        "ICU_Net.VE(('V', 'H', 'S', 'L', 'O', 'A', 'T', 'B', 'C'))\n",
        "print(adds)\n",
        "print(muls)\n",
        "\n",
        "adds = 0\n",
        "muls = 0\n",
        "ICU_Net.VE(ICU_Net.minDegree())\n",
        "print(adds)\n",
        "print(muls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE3RgwPSQ07k"
      },
      "source": [
        "# Answering Queries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qSwKIMGQ07k"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Now it's your turn to implement a function `query` that receives as arguments:\n",
        "\n",
        "1. A list of query variables\n",
        "2. and a list of evidence\n",
        "\n",
        "and returns $P(\\text{variables}|\\text{evidence})$.\n",
        "\n",
        "Before you start, some important observations:\n",
        "\n",
        "* You will need to change some of the factors in the `factors` dict to set evidence on them. For this reason, we created a backup and restored the `factors` dict after the operation.\n",
        "* Remove the query variables from the elimination order list.\n",
        "* It is up to you if you want to remove the evidence variables from the elimination list.\n",
        "* A final normalisation step will answer queries in the format $P(Q|e)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11ehssaXQ07k"
      },
      "outputs": [],
      "source": [
        "class BayesNet(BayesNet):\n",
        "    def query(self, q_vars, **q_evi):\n",
        "        '''\n",
        "        A faster VE-based query function\n",
        "        Returns a factor P(q_vars| q_evi)\n",
        "        '''\n",
        "        # backup factors dict\n",
        "        backup_factors = copy.deepcopy(self.factors)\n",
        "\n",
        "        ... # TODO ~11 lines\n",
        "\n",
        "        # restore original factors\n",
        "        self.factors = backup_factors\n",
        "\n",
        "        # Return factor P(q_vars | q_evi)\n",
        "        return ... # TODO\n",
        "\n",
        "#########################\n",
        "# Test code\n",
        "#########################\n",
        "\n",
        "# reinitialise ICU_net so that it has the new query function\n",
        "ICU_Net = BayesNet(ICU_Net.graph, ICU_Net.outcomeSpace, ICU_Net.factors)\n",
        "\n",
        "print(ICU_Net.query('L', C=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYemnRNKQ07k"
      },
      "source": [
        "If your implementation is correct then you should see the following output:\n",
        "\n",
        "```\n",
        "╒═════╤═══════════╕\n",
        "│   L │        Pr │\n",
        "╞═════╪═══════════╡\n",
        "│   0 │ 0.947722  │\n",
        "├─────┼───────────┤\n",
        "│   1 │ 0.0522777 │\n",
        "╘═════╧═══════════╛\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecgo2dXRQ07k"
      },
      "source": [
        "# Final Step\n",
        "\n",
        "Go back through the notebook and copy your solutions into your BayesNet.py file for future use. Your VE function won't need to keep track of additions and multiplications in future, so you can delete these computations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsalY6S-Q07k"
      },
      "source": [
        "# Challenge Exercise\n",
        "\n",
        "The Variable Elimination function implemented above loops over every variable in the elimination order, and has an inner loop over all factors to find the factors to be eliminated in each step. This algorithm takes $O(n^2)$ where $n$ is the size of the graph (ignoring the cost of joining and marginalising factors, which is usually the main cost).\n",
        "\n",
        "Use an additional data structure to improve your VE implementation to be $O(n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv-78GK1Q07l"
      },
      "source": [
        "That is all for today. See you next week!"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "198px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_position": {
        "height": "783px",
        "left": "0px",
        "right": "1346.87px",
        "top": "108px",
        "width": "212px"
      },
      "toc_section_display": "block",
      "toc_window_display": true,
      "widenNotebook": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}